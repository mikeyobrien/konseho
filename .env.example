# Konseho Model Provider Configuration
# Copy this file to .env and fill in your API keys

# For OpenAI
OPENAI_API_KEY=your-openai-api-key-here

# For Anthropic (Claude)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# For AWS Bedrock (if not using default AWS credentials)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_DEFAULT_REGION=us-east-1

# For Ollama (local models)
OLLAMA_HOST=http://localhost:11434

# Default model selection
# Options: openai, anthropic, bedrock, ollama, litellm
DEFAULT_PROVIDER=anthropic
DEFAULT_MODEL=claude-3-opus-20240229