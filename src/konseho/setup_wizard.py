"""First-run setup wizard for Konseho."""
from __future__ import annotations

import os
import sys
from pathlib import Path


def run_setup_wizard() -> None:
    """Run interactive setup wizard for first-time users."""
    print('\nüèõÔ∏è  Welcome to Konseho Setup Wizard')
    print('=' * 50)
    print("Let's set up your model provider.\n")
    env_path = Path('.env')
    if env_path.exists():
        response = input('Found existing .env file. Overwrite? (y/N): ')
        if response.lower() != 'y':
            print('Setup cancelled.')
            return
    print('Available providers:')
    print('1. Anthropic (Claude) - Recommended')
    print('2. OpenAI (GPT)')
    print('3. AWS Bedrock')
    print('4. Ollama (Local)')
    choice = input('\nSelect provider (1-4) [1]: ').strip() or '1'
    providers = {'1': ('anthropic', 'ANTHROPIC_API_KEY',
        'claude-3-opus-20240229'), '2': ('openai', 'OPENAI_API_KEY',
        'gpt-4'), '3': ('bedrock', None,
        'anthropic.claude-3-sonnet-20240229-v1:0'), '4': ('ollama', None,
        'llama2')}
    if choice not in providers:
        print('Invalid choice. Using Anthropic.')
        choice = '1'
    provider, key_name, default_model = providers[choice]
    api_key = None
    if key_name:
        print(f"\nYou'll need an API key for {provider.title()}.")
        if provider == 'anthropic':
            print('Get one at: https://console.anthropic.com/settings/keys')
        elif provider == 'openai':
            print('Get one at: https://platform.openai.com/api-keys')
        api_key = input(f'\nEnter your {key_name}: ').strip()
        if not api_key:
            print(
                "\n‚ö†Ô∏è  No API key provided. You'll need to add it to .env later."
                )
    env_content = f"""# Konseho Model Provider Configuration
# Generated by setup wizard

DEFAULT_PROVIDER={provider}
DEFAULT_MODEL={default_model}
"""
    if api_key:
        env_content += f'{key_name}={api_key}\n'
    if provider == 'bedrock':
        env_content += """
# AWS Bedrock uses your AWS credentials
# Make sure AWS CLI is configured or set:
# AWS_ACCESS_KEY_ID=your-key
# AWS_SECRET_ACCESS_KEY=your-secret
# AWS_DEFAULT_REGION=us-east-1
"""
    elif provider == 'ollama':
        env_content += """
# Ollama configuration
OLLAMA_HOST=http://localhost:11434

# Make sure Ollama is running:
# ollama serve
# ollama pull llama2
"""
    env_content += '\n# Model parameters\nTEMPERATURE=0.7\nMAX_TOKENS=2000\n'
    with open('.env', 'w') as f:
        f.write(env_content)
    print('\n‚úÖ Configuration saved to .env')
    gitignore_path = Path('.gitignore')
    if gitignore_path.exists():
        content = gitignore_path.read_text()
        if '.env' not in content:
            with open('.gitignore', 'a') as f:
                f.write('\n# Environment files\n.env\n')
            print('‚úÖ Added .env to .gitignore')
    print(f'\nüì¶ Checking if {provider} provider is installed...')
    try:
        if provider == 'anthropic':
            import strands.models.anthropic
            print('‚úÖ Anthropic provider is installed')
        elif provider == 'openai':
            import strands.models.openai
            print('‚úÖ OpenAI provider is installed')
        else:
            print(f'‚úÖ {provider.title()} provider ready')
    except ImportError:
        print(f'\n‚ö†Ô∏è  {provider.title()} provider not installed.')
        print(f'Install with: pip install konseho[{provider}]')
        response = input('\nInstall now? (Y/n): ').strip().lower()
        if response != 'n':
            os.system(f'{sys.executable} -m pip install konseho[{provider}]')
    print('\nüéâ Setup complete!')
    print('\nYou can now run:')
    print('  python -m konseho        # Start interactive chat')
    print('  python -m konseho --config  # Check configuration')


if __name__ == '__main__':
    run_setup_wizard()
